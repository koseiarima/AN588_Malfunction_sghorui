---
title: "sghorui_OriginalHomeworkCode_04"
author: "Soumalya"
format: html
editor: visual
---

# **What‚Äôs Your Malfunction?**

Create a new *GitHub* repo and git-referenced *Rstudio* Project called ‚ÄúAN588_Malfunction_BUlogin‚Äù. Within that repo, create a new `.Rmd` file called ‚ÄúBUlogin_OriginalHomeworkCode_04‚Äù. Don‚Äôt forget to add your [Peer Group](https://fuzzyatelin.github.io/bioanth-stats/peercommentary.html) and instructor as collaborators, and to accept their invitations to you. Making sure to push both the markdown and knitted `.html` files to your repository, do the following:

Here's the first question:

### \[1\] Write a simple R function, `Z.prop.test()`, that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:

-   Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default ‚Äútwo.sided‚Äù) and conf.level (default 0.95), to be used in the same way as in the function `t.test()`.

-   When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=‚Äúless‚Äù or alternative=‚Äúgreater‚Äù, the same as in the use of x and y in the function `t.test()`.

-   The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

-   The function should contain a check for the rules of thumb we have talked about (ùëõ‚àóùëù>5n‚àóp>5 and ùëõ‚àó(1‚àíùëù)>5n‚àó(1‚àíp)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

-   The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

So, let's do this!

I will start by defining the function Z.prop.test:

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) 
  {
  check_normality <- function(p, n) # this function will check if the sample size is large enough for the normal approximation to work.
    {
    if (n * p < 5 || n * (1 - p) < 5) 
      {
      warning("Normal approximation may not be valid: n*p or n*(1-p) is less than 5.") # Here I am checking the rules of thumb: np > 5 and n(1-p) > 5. If these conditions are not met, it will send the above warning.
    }
  }
```

### **One Sample Z-test:**

If I am only testing one sample (i.e., p2 or n2 is NULL), I will perform a one-sample Z-test.

```{r}
# One-sample Z-test
  if (is.null(p2) || is.null(n2)) 
    {
    # Check if the data is valid
    check_normality(p1, n1)
    
    # Calculate the standard error
    se <- sqrt(p0 * (1 - p0) / n1)
    
    # Calculate the Z statistic
    Z <- (p1 - p0) / se
    
    # Calculate the p-value based on the alternative hypothesis
    if (alternative == "two.sided") 
      {
      P <- 2 * pnorm(-abs(Z))  # Two-tailed test
    } 
    else if (alternative == "less") 
      {
      P <- pnorm(Z)  # Left-tailed test
    } 
    else if (alternative == "greater") 
      {
      P <- pnorm(-Z)  # Right-tailed test
    } 
    else 
      {
      stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
    }
    
    # Calculate the confidence interval
    alpha <- 1 - conf.level
    z_alpha <- qnorm(1 - alpha / 2)
    CI <- c(p1 - z_alpha * se, p1 + z_alpha * se)
  }
```

The function starts by checking if the data is valid for a Z-test using a helper function. It calculates the standard error (se), which measures how much the sample proportion (p1) might vary from the true population proportion (p0). Next, it computes the Z statistic, which tells us how far p1 is from p0 in terms of standard errors. The p-value is then calculated to show how likely it is to see a result as extreme as p1 if the true proportion is p0. This depends on the alternative hypothesis: "two-sided" tests if p1 is different from p0 (higher or lower), "less" tests if p1 is less than p0, and "greater" tests if p1 is greater than p0. Finally, the confidence interval (CI) gives a range of values where we‚Äôre fairly confident the true proportion lies.

### Two-Sample Z-Test:

If I am comparing two samples (i.e., both p2 and n2 are provided), we perform a two-sample Z-test.

```{r}
# Two-sample Z-test
  else 
    {
    # Check if the data is valid for both samples
    check_normality(p1, n1)
    check_normality(p2, n2)
    
    # Calculate the pooled proportion
    pooled_p <- (p1 * n1 + p2 * n2) / (n1 + n2)
    
    # Calculate the standard error
    se <- sqrt(pooled_p * (1 - pooled_p) * (1 / n1 + 1 / n2))
    
    # Calculate the Z statistic
    Z <- (p1 - p2) / se
    
    # Calculate the p-value based on the alternative hypothesis
    if (alternative == "two.sided") 
      {
      P <- 2 * pnorm(-abs(Z))  # Two-tailed test
    } 
    else if (alternative == "less") 
      {
      P <- pnorm(Z)  # Left-tailed test (p1 < p2)
    } 
    else if (alternative == "greater") 
      {
      P <- pnorm(-Z)  # Right-tailed test (p1 > p2)
    } 
    else 
      {
      stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
    }
    
    # Calculate the confidence interval for the difference in proportions
    alpha <- 1 - conf.level
    z_alpha <- qnorm(1 - alpha / 2)
    CI <- c((p1 - p2) - z_alpha * se, (p1 - p2) + z_alpha * se)
  }
```

The function first checks if both samples are valid for a Z-test. It then calculates the **pooled proportion**, which combines the proportions from both samples to estimate a common proportion under the null hypothesis. Next, it computes the **standard error (se)**, which measures how much the difference between p1 and p2 might vary. The **Z statistic** tells us how far p1 is from p2 in terms of standard errors. The **p-value** shows how likely it is to see a difference as extreme as p1-p2 if there‚Äôs no real difference between the groups. Finally, the **confidence interval (CI)** gives a range of values for the difference between p1 and p2.

Now the results:

```{r}
# Return the results as a list
  return(list(Z = Z, P = P, CI = CI))
}
```

Now, to run this entire the above code properly, we have to run it as a single chunk.

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) 
  {
  # Helper function to check if the normal approximation is valid
  check_normality <- function(p, n) 
    {
    if (n * p < 5 || n * (1 - p) < 5) 
      {
      warning("Normal approximation may not be valid: n*p or n*(1-p) is less than 5.")
    }
  }
  # One-sample Z-test
  if (is.null(p2) || is.null(n2)) 
    {
    # Check if the data is valid
    check_normality(p1, n1)
    
    # Calculate the standard error
    se <- sqrt(p0 * (1 - p0) / n1)
    
    # Calculate the Z statistic
    Z <- (p1 - p0) / se
    
    # Calculate the p-value based on the alternative hypothesis
    if (alternative == "two.sided") 
      {
      P <- 2 * pnorm(-abs(Z))  # Two-tailed test
    } 
    else if (alternative == "less") 
      {
      P <- pnorm(Z)  # Left-tailed test
    } 
    else if (alternative == "greater") 
      {
      P <- pnorm(-Z)  # Right-tailed test
    } 
    else 
      {
      stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
    }
    
    # Calculate the confidence interval
    alpha <- 1 - conf.level
    z_alpha <- qnorm(1 - alpha / 2)
    CI <- c(p1 - z_alpha * se, p1 + z_alpha * se)
  }
  
  # Two-sample Z-test
  else 
    {
    # Check if the data is valid for both samples
    check_normality(p1, n1)
    check_normality(p2, n2)
    
    # Calculate the pooled proportion
    pooled_p <- (p1 * n1 + p2 * n2) / (n1 + n2)
    
    # Calculate the standard error
    se <- sqrt(pooled_p * (1 - pooled_p) * (1 / n1 + 1 / n2))
    
    # Calculate the Z statistic
    Z <- (p1 - p2) / se
    
    # Calculate the p-value based on the alternative hypothesis
    if (alternative == "two.sided") 
      {
      P <- 2 * pnorm(-abs(Z))  # Two-tailed test
    } 
    else if (alternative == "less") 
      {
      P <- pnorm(Z)  # Left-tailed test (p1 < p2)
    } 
    else if (alternative == "greater") 
      {
      P <- pnorm(-Z)  # Right-tailed test (p1 > p2)
    } 
    else 
      {
      stop("Invalid alternative hypothesis. Use 'two.sided', 'less', or 'greater'.")
    }
    
    # Calculate the confidence interval for the difference in proportions
    alpha <- 1 - conf.level
    z_alpha <- qnorm(1 - alpha / 2)
    CI <- c((p1 - p2) - z_alpha * se, (p1 - p2) + z_alpha * se)
    }
  # Return the results as a list
  return(list(Z = Z, P = P, CI = CI))
}
```

An example:

```{r}
# One-sample test
result1 <- Z.prop.test(p1 = 0.6, n1 = 100, p0 = 0.5, alternative = "two.sided")
print(result1)

# Two-sample test
result2 <- Z.prop.test(p1 = 0.6, n1 = 100, p2 = 0.5, n2 = 120, alternative = "greater")
print(result2)
```

Here is the 2nd question:

### \[2\] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (`MaxLongevity_m`) measured in months from species‚Äô brain size (`Brain_Size_Species_Mean`) measured in grams. Do the following for both `longevity~brain size` and `log(longevity)~log(brain size)`:

-   Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function `geom_text()`).

-   Identify and interpret the point estimate of the slope (Œ≤1), as well as the outcome of the test associated with the hypotheses H0: Œ≤1 = 0; HA: Œ≤1 ‚â† 0. Also, find a 90 percent CI for the slope (Œ≤1) parameter.

-   Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

-   Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

-   Looking at your two models, which do you think is better? Why?

### Loading the libraries and the data from Kamilar and Cooper

```{r}
# Loading necessary libraries
library(ggplot2)  # For plotting
library(dplyr)    # For data manipulation

# Loading the dataset
library(curl)
data <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/KamilarAndCooperData.csv")
KC <- read.csv(data, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(KC)
```
